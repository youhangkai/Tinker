{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c166c28",
   "metadata": {},
   "source": [
    "# Download GLanCE 30 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b9ab2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9052/9052 [1:23:16<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2001Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2001_land_cover\"\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac51e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▌                                                                            | 314/15841 [01:54<54:23,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download: GLANCE30_A20020701_h36v23_001_20220824_NA_LC.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:04:59<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2002Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2002_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e401a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:02:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2003Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2003_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec083c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:01:50<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2004Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2004_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27bbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:02:06<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2005Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2005_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131562c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:02:24<00:00,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2006Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2006_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e56b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:02:09<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2007Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2007_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b500e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:02:37<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2008Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2008_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01211590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:00:06<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2009Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2009_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b2e7cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:50<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2010Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2010_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc38eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:01:29<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2011Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2011_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b768906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:03<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2012Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2012_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36d1957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████▋                       | 10975/15841 [41:37<14:21,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download: GLANCE30_A20130701_h22v13_001_20220824_NA_LC.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:16<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2013Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2013_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ca5356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:19<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2014Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2014_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09c0cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:56<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2015Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2015_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fc7a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:00:10<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2016Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2016_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de2eec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 15841/15841 [1:00:09<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2017Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2017_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f696e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [59:31<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2018Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2018_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81473b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 15841/15841 [58:56<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Your NASA Earthdata token\n",
    "TOKEN = \"eyJ0eXAiOiJKV1QiLCJvcmlnaW4iOiJFYXJ0aGRhdGEgTG9naW4iLCJzaWciOiJlZGxqd3RwdWJrZXlfb3BzIiwiYWxnIjoiUlMyNTYifQ.eyJ0eXBlIjoiVXNlciIsInVpZCI6ImhhbmdrYWl5b3UiLCJleHAiOjE3MDM0NTQwMjMsImlhdCI6MTY5ODI3MDAyMywiaXNzIjoiRWFydGhkYXRhIExvZ2luIn0.iMENMRmEBRdsDL0SDZpmyx-uAYCJcx_9ILS9v5AIM8MF96O04mYCoVnUsc-pbTC4FbCuk1K4EtV5zrOHd97ctY73xCTalTw6hriOMnMR0TAq5tFJGu99Pltb105yp9HfR4pR3y0BPt7xJ1yKfu3gng_GmzOmmWPICFKYEr5a0sjcwGCddIJ_NQPLonDWEeLxVAfb4aJTTozRaPuR9Zhfj_M44HjFK1fhQtfuuJZDy0IBU6hfTknPEVV5lvTTyRC10NMG59aZj_Zswp9PAC50F9cLCU3dcMF37WsUIV8n4wvfvRvnb5ezgG_3esEZeHhBrlCG_GljMypVlC8KKC441A\"\n",
    "\n",
    "# Define headers for the request\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {TOKEN}\"\n",
    "}\n",
    "\n",
    "# File paths\n",
    "TXT_FILE_PATH = \"G:\\\\Hangkai\\\\Download\\\\2019Download.txt\"\n",
    "DOWNLOAD_DIR = \"G:\\\\Hangkai\\\\Glance30\\\\2019_land_cover\"\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# Reading and downloading files\n",
    "with open(TXT_FILE_PATH, 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        filename = url.split('/')[-1].strip()\n",
    "\n",
    "        if filename.endswith('LC.tif'): # Since I just want to download tifs end with \"LC\"\n",
    "            response = requests.get(url.strip(), headers=HEADERS)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                download_path = os.path.join(DOWNLOAD_DIR, filename)\n",
    "                with open(download_path, 'wb') as download_file:\n",
    "                    download_file.write(response.content)\n",
    "                # print(f\"Downloaded: {filename}\")\n",
    "            else:\n",
    "                print(f\"Failed to download: {filename}\")\n",
    "\n",
    "print(\"Download completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
